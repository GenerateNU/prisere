{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2094ecb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q pandas numpy scikit-learn sentence-transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "\n",
    "purchases_df = pd.read_csv(\"purchases.csv\")\n",
    "## lineItems_df = pd.read_csv(\"lineItems.csv\") not being used yet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78510da6",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING OF CSVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ac9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# this is for analysis against amounts of other categories \n",
    "\n",
    "categories = purchases_df[\"Category\"].dropna().unique().tolist()\n",
    "\n",
    "# sentence transformer to find relations between categories\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# embeddings for each category string\n",
    "cat_embeddings = model.encode(categories, convert_to_numpy=True)\n",
    "\n",
    "# cosine similarity matrix between all categories\n",
    "sim_matrix = cosine_similarity(cat_embeddings)\n",
    "\n",
    "## what is the threshold for being similar as categories?\n",
    "similarity_threshold = 0.6\n",
    "\n",
    "related_groups = {}\n",
    "for i, cat in enumerate(categories):\n",
    "    related_idx = [\n",
    "        j for j in range(len(categories)) \n",
    "        if sim_matrix[i, j] >= similarity_threshold\n",
    "    ]\n",
    "    related_cats = [categories[j] for j in related_idx]\n",
    "    related_groups[cat] = related_cats\n",
    "\n",
    "# stats over the related categories for each category\n",
    "rel_stats = {}\n",
    "for cat, rel_cats in related_groups.items():\n",
    "    mask = purchases_df[\"Category\"].isin(rel_cats)\n",
    "    amounts = purchases_df.loc[mask, \"Amount\"]\n",
    "    rel_stats[cat] = {\n",
    "        \"rel_mean\": amounts.mean(),\n",
    "        \"rel_std\": amounts.std()\n",
    "    }\n",
    "\n",
    "purchases_df[\"rel_mean\"] = purchases_df[\"Category\"].map(lambda c: rel_stats[c][\"rel_mean\"])\n",
    "purchases_df[\"rel_std\"]  = purchases_df[\"Category\"].map(lambda c: rel_stats[c][\"rel_std\"])\n",
    "\n",
    "purchases_df[\"rel_std\"] = purchases_df[\"rel_std\"].replace(0, np.nan)\n",
    "\n",
    "# Z-score of amount relative to \"semantically related\" category group\n",
    "purchases_df[\"z_amount_related\"] = (\n",
    "    (purchases_df[\"Amount\"] - purchases_df[\"rel_mean\"]) / purchases_df[\"rel_std\"]\n",
    ")\n",
    "purchases_df[\"z_amount_related\"] = purchases_df[\"z_amount_related\"].fillna(0.0)\n",
    "\n",
    "\n",
    "global_q90 = purchases_df[\"Amount\"].quantile(0.90)\n",
    "global_q95 = purchases_df[\"Amount\"].quantile(0.95)\n",
    "\n",
    "purchases_df[\"is_large_global\"] = (purchases_df[\"Amount\"] > global_q90).astype(int)\n",
    "purchases_df[\"is_very_large_global\"] = (purchases_df[\"Amount\"] > global_q95).astype(int)\n",
    "\n",
    "\n",
    "if \"label\" in purchases_df.columns:\n",
    "    purchases_df[\"y_label\"] = purchases_df[\"label\"].map({\"typical\": 0, \"extraneous\": 1})\n",
    "\n",
    "\n",
    "# seasonality analysis\n",
    "\n",
    "purchases_df[\"Date\"] = pd.to_datetime(purchases_df[\"Date\"], format=\"ISO8601\")\n",
    "purchases_df[\"Month\"] = purchases_df[\"Date\"].dt.month\n",
    "purchases_df[\"DayOfWeek\"] = purchases_df[\"Date\"].dt.dayofweek\n",
    "purchases_df[\"YearMonth\"] = purchases_df[\"Date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "purchases_df[\"month_cat_count\"] = purchases_df.groupby([\"YearMonth\",\"Category\"])[\"Transaction_ID\"].transform(\"count\")\n",
    "purchases_df[\"month_total\"] = purchases_df.groupby(\"YearMonth\")[\"Transaction_ID\"].transform(\"count\")\n",
    "\n",
    "purchases_df[\"month_cat_share\"] = purchases_df[\"month_cat_count\"] / purchases_df[\"month_total\"]\n",
    "purchases_df[\"category_freq\"] = purchases_df.groupby(\"Category\")[\"Transaction_ID\"].transform(\"count\")\n",
    "\n",
    "feature_cols = [\n",
    "    \"Amount\",\n",
    "    \"z_amount_related\",\n",
    "    \"is_large_global\",\n",
    "    \"is_very_large_global\",\n",
    "    \"month_cat_share\",\n",
    "    \"category_freq\",\n",
    "    ### MISSING THE SEASONAL FUNCTIONALITY\n",
    "    \n",
    "]\n",
    "\n",
    "purchases_model = purchases_df.dropna(subset=[\"y_label\"]).copy()\n",
    "\n",
    "x = purchases_model[feature_cols].values \n",
    "y = purchases_model[\"y_label\"].values  \n",
    "\n",
    "\n",
    "x_train, x_rest, y_train, y_rest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_rest, y_rest, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71afd5",
   "metadata": {},
   "source": [
    "## Find the best poly fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fedaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9865196078431373, 0.991421568627451, 0.9926470588235294, 0.9963235294117647, 0.9963235294117647]\n",
      "[0.9901960784313726, 0.9901960784313726, 0.9803921568627451, 0.9803921568627451, 0.9901960784313726]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree=1, include_bias=False)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_val_poly   = poly.transform(x_val)\n",
    "\n",
    "    \n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(x_train_poly, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132f296",
   "metadata": {},
   "source": [
    "## Save coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a7ddabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['extraneous_model.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "artifacts = {\n",
    "    \"model\": clf,\n",
    "    \"scaler\": scaler,\n",
    "    \"poly\": poly,\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"rel_stats\": rel_stats,\n",
    "    \"global_q90\": global_q90,\n",
    "    \"global_q95\": global_q95,\n",
    "}\n",
    "\n",
    "joblib.dump(artifacts, \"extraneous_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
